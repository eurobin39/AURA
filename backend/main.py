import os
import requests
import time
import cv2
from dotenv import load_dotenv


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

API_KEY = os.getenv("FACE_APIKEY")
ENDPOINT = os.getenv("FACE_API_ENDPOINT")

BACKEND_URL = "http://127.0.0.1:5001"
face_api_url = f"{ENDPOINT}/face/v1.0/detect"

# API ìš”ì²­ ì„¤ì •
headers = {"Ocp-Apim-Subscription-Key": API_KEY, "Content-Type": "application/octet-stream"}
params = {
    "returnFaceAttributes": "headPose,blur,exposure,occlusion,emotion",  # emotion ì¶”ê°€
    "detectionModel": "detection_01"
}

def analyze_face(image_path):
    """Azure Face APIë¡œ ì´ë¯¸ì§€ ë¶„ì„"""
    try:
        with open(image_path, "rb") as image_file:
            response = requests.post(face_api_url, headers=headers, params=params, data=image_file)
        
        if response.status_code == 200:
            faces = response.json()
            return faces if faces else None
        else:
            print(f"âŒ API ì˜¤ë¥˜: {response.status_code} - {response.text}")
            return None
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

def estimate_efficiency(faces):
    """ì—…ë¬´ íš¨ìœ¨ì„± ë¶„ì„"""
    if not faces:
        return {
            "efficiency_score": 0,
            "details": "No face detected",
            "focus": "N/A",
            "fatigue": "N/A",
            "emotion": "N/A"
        }

    # ì²« ë²ˆì§¸ ì–¼êµ´ ë°ì´í„° ì‚¬ìš©
    face = faces[0]
    attributes = face.get("faceAttributes", {})

    # 1. ì´ˆì (Focus) ê³„ì‚°: ë¨¸ë¦¬ ìì„¸(headPose) ê¸°ë°˜
    head_pose = attributes.get("headPose", {})
    yaw, pitch = head_pose.get("yaw", 0), head_pose.get("pitch", 0)
    focus_score = 100 - (abs(yaw) + abs(pitch))  # íšŒì „ì´ ì ì„ìˆ˜ë¡ ì´ˆì  ë†’ìŒ
    focus_score = max(0, min(100, focus_score))  # 0~100 ë²”ìœ„ë¡œ ì œí•œ

    # 2. í”¼ë¡œë„(Fatigue) ì¶”ì •: ëˆˆ ê°€ë¦¼, íë¦¼ë„ í™œìš©
    occlusion = attributes.get("occlusion", {})
    blur = attributes.get("blur", {})
    eye_occluded = occlusion.get("eyeOccluded", False)
    blur_level = blur.get("value", "Low")  # Low, Medium, High
    fatigue_score = 0
    if eye_occluded:
        fatigue_score += 50  # ëˆˆ ê°€ë¦¼ ì‹œ í”¼ë¡œë„ ì¦ê°€
    if blur_level == "High":
        fatigue_score += 30  # íë¦¼ì´ ì‹¬í•˜ë©´ í”¼ë¡œ ê°€ëŠ¥ì„±
    fatigue_score = min(100, fatigue_score)

    # 3. ê°ì •(Emotion) ë¶„ì„: ê¸ì •ì  ê°ì •ì€ íš¨ìœ¨ì„±ì— ê¸°ì—¬
    emotion = attributes.get("emotion", {})
    positive_emotion = emotion.get("happiness", 0) + emotion.get("neutral", 0)
    negative_emotion = emotion.get("sadness", 0) + emotion.get("anger", 0) + emotion.get("fear", 0)
    emotion_factor = positive_emotion - negative_emotion  # -1 ~ 1 ì‚¬ì´ ê°’
    emotion_factor = max(-1, min(1, emotion_factor)) * 20  # -20 ~ 20 ì ìˆ˜í™”

    # 4. ì¢…í•© íš¨ìœ¨ì„± ì ìˆ˜ ê³„ì‚°
    efficiency_score = (focus_score * 0.5) - (fatigue_score * 0.3) + emotion_factor
    efficiency_score = max(0, min(100, efficiency_score))  # 0~100ìœ¼ë¡œ ì œí•œ

    # ê²°ê³¼ ë°˜í™˜
    return {
        "efficiency_score": round(efficiency_score, 1),
        "details": {
            "focus": f"{focus_score:.1f}% (Yaw: {yaw}, Pitch: {pitch})",
            "fatigue": f"{fatigue_score}% (Eyes occluded: {eye_occluded}, Blur: {blur_level})",
            "emotion": f"Positive: {positive_emotion:.2f}, Negative: {negative_emotion:.2f}"
        }
    }

if __name__ == "__main__":
    image_path = "face_euro.jpg"  # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
    print(f"ğŸ” ë¶„ì„ ì‹œì‘: {image_path}")
    faces = analyze_face(image_path)
    
    if faces:
        result = estimate_efficiency(faces)
        print(f"ğŸ“Š ì—…ë¬´ íš¨ìœ¨ì„± ì ìˆ˜: {result['efficiency_score']}%")
        print("ì„¸ë¶€ ì •ë³´:")
        for key, value in result["details"].items():
            print(f"  {key}: {value}")
    else:
        print("âš ï¸ ë¶„ì„ ì‹¤íŒ¨: ì–¼êµ´ ë°ì´í„° ì—†ìŒ")